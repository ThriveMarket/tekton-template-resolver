name: CI/CD Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      force_full_build:
        description: 'Force full build pipeline (bypass Go change detection)'
        required: false
        type: boolean
        default: true

# Permissions needed for GitHub workflows
permissions:
  contents: read
  packages: write
  id-token: write # Needed for keyless signing
  actions: read

jobs:
  check-go-changes:
    name: Check for Go changes
    runs-on: ubuntu-latest
    outputs:
      go-changed: ${{ steps.set-output.outputs.go-changed }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check for Go file changes
        uses: dorny/paths-filter@v2
        id: filter
        with:
          filters: |
            go:
              - '**/*.go'
              - 'go.mod'
              - 'go.sum'
              - '.golangci.yml'
              - 'vendor/**'
              - 'Dockerfile'
      
      - name: Set output based on changes or manual trigger
        id: set-output
        env:
          EVENT_NAME: ${{ github.event_name }}
          FORCE_FULL_BUILD: ${{ github.event.inputs.force_full_build }}
          GO_CHANGED: ${{ steps.filter.outputs.go }}
        run: |
          # Set to true if workflow was manually triggered with force_full_build
          if [[ "$EVENT_NAME" == "workflow_dispatch" && "$FORCE_FULL_BUILD" == "true" ]]; then
            echo "Force full build requested via manual trigger"
            echo "go-changed=true" >> $GITHUB_OUTPUT
          else
            # Use the result from the paths-filter
            echo "go-changed=$GO_CHANGED" >> $GITHUB_OUTPUT
          fi
          
      - name: Show change status
        run: |
          echo "Go files changed or forced build: ${{ steps.set-output.outputs.go-changed }}"

  lint:
    name: Code Linting
    runs-on: ubuntu-latest
    needs: check-go-changes
    if: needs.check-go-changes.outputs.go-changed == 'true'
    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v4
        with:
          go-version: '1.24'
          cache: true

      - name: Run golangci-lint
        uses: golangci/golangci-lint-action@v7
        with:
          version: v2.0
          args: --timeout=5m ./cmd/...

  test:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: check-go-changes
    if: needs.check-go-changes.outputs.go-changed == 'true'
    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v4
        with:
          go-version: '1.24'
          cache: true

      - name: Run tests
        run: go test ./... -v

      - name: Generate coverage report
        run: go test ./... -coverprofile=coverage.out

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: coverage.out

  build:
    name: Build Container
    runs-on: ubuntu-latest
    needs: [check-go-changes, lint, test]
    if: always() # Run even if lint/test are skipped or failed
    steps:
      - uses: actions/checkout@v4

      # Skip the build if required steps failed (but not if they were skipped)
      - name: Check previous step results
        id: check
        run: |
          if [ "${{ contains(needs.*.result, 'failure') }}" = "true" ]; then
            echo "Previous steps failed, skipping build"
            exit 1
          fi
          
          # Check if we should build based on changes
          if [ "${{ needs.check-go-changes.outputs.go-changed }}" != "true" ]; then
            echo "No Go changes detected, using existing container image"
            echo "skip=true" >> $GITHUB_OUTPUT
          else
            echo "Go changes detected, building new container image"
            echo "skip=false" >> $GITHUB_OUTPUT
          fi

      - name: Set up Go
        if: steps.check.outputs.skip != 'true'
        uses: actions/setup-go@v4
        with:
          go-version: '1.24'
          cache: true

      - name: Install ko
        if: steps.check.outputs.skip != 'true'
        run: |
          curl -L https://github.com/google/ko/releases/download/v0.15.1/ko_0.15.1_Linux_x86_64.tar.gz | tar xzf - ko
          chmod +x ./ko
          sudo mv ko /usr/local/bin/

      - name: Set up Docker Buildx
        if: steps.check.outputs.skip != 'true'
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        if: steps.check.outputs.skip != 'true' && github.event_name != 'pull_request'
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push container image
        if: steps.check.outputs.skip != 'true'
        id: docker_build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          push: ${{ github.event_name != 'pull_request' }}
          tags: |
            ghcr.io/thrivemarket/template-resolver:latest
            ghcr.io/thrivemarket/template-resolver:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  e2e-test:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: [check-go-changes, build]
    if: always() && !contains(needs.*.result, 'failure')
    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v4
        with:
          go-version: '1.24'
          cache: true

      - name: Install Task
        run: |
          sh -c "$(curl --location https://taskfile.dev/install.sh)" -- -d -b /usr/local/bin

      - name: Install ko
        run: |
          curl -L https://github.com/google/ko/releases/download/v0.15.1/ko_0.15.1_Linux_x86_64.tar.gz | tar xzf - ko
          chmod +x ./ko
          sudo mv ko /usr/local/bin/

      - name: Create kind cluster
        uses: helm/kind-action@v1.12.0
        with:
          cluster_name: kind

      - name: Install Tekton Pipelines
        run: task install:tekton

      - name: Build and deploy resolver
        run: |
          # Debug image references before starting
          echo "Debugging image references..."
          cat config/deployment.yaml
          
          # Always build locally for all CI runs (both PRs and pushes to main)
          # This ensures we don't need to pull from ghcr.io which requires auth
          echo "Building local image with ko"
          export KO_DOCKER_REPO=ko.local
          
          # Build the image
          IMAGE_REF=$(ko build --local -B thrivemarket.com/template-resolver/cmd/template-resolver)
          echo "Built image: $IMAGE_REF"
          
          # Load the image directly into kind
          echo "Loading image into kind cluster"
          kind load docker-image "$IMAGE_REF" --name=kind
          
          # Update the deployment file with the local image
          sed -i "s|image:.*|image: $IMAGE_REF|g" config/deployment.yaml
          
          # Show the updated deployment file
          echo "Updated deployment file:"
          cat config/deployment.yaml
          
          # Apply with namespace check
          kubectl create namespace tekton-pipelines-resolvers --dry-run=client -o yaml | kubectl apply -f -
          kubectl apply -f config/
          
          # Verify pod status
          echo "Checking pod status:"
          kubectl get pods -n tekton-pipelines-resolvers
          sleep 5
          kubectl get pods -n tekton-pipelines-resolvers

      - name: Make sure tekton pipeline resolver pod is running
        run: |
          # Check if resolver pods are running correctly
          echo "Checking resolver pod status:"
          kubectl get pods -n tekton-pipelines-resolvers -l app=template-resolver -o wide
          
          # Debug any pod issues
          RESOLVER_POD=$(kubectl get pods -n tekton-pipelines-resolvers -l app=template-resolver -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)
          if [ -n "$RESOLVER_POD" ]; then
            echo "Checking pod events:"
            kubectl describe pod -n tekton-pipelines-resolvers "$RESOLVER_POD"
            
            # Check if pod is failing to pull image
            CONTAINER_STATUS=$(kubectl get pod -n tekton-pipelines-resolvers "$RESOLVER_POD" -o jsonpath='{.status.containerStatuses[0].state.waiting.reason}' 2>/dev/null)
            if [ "$CONTAINER_STATUS" = "ImagePullBackOff" ] || [ "$CONTAINER_STATUS" = "ErrImagePull" ]; then
              echo "Image pull issue detected. Retrying with a local build..."
              
              # Rebuild with ko and try again
              export KO_DOCKER_REPO=ko.local
              IMAGE_REF=$(ko build --local -B thrivemarket.com/template-resolver/cmd/template-resolver)
              echo "Built image: $IMAGE_REF"
              
              # Load into kind and update deployment
              kind load docker-image "$IMAGE_REF" --name=kind
              kubectl set image deployment/template-resolver -n tekton-pipelines-resolvers controller="$IMAGE_REF"
              
              # Wait for pod to start
              echo "Waiting for resolver pod to become ready..."
              kubectl rollout status deployment/template-resolver -n tekton-pipelines-resolvers --timeout=2m
            fi
          else
            echo "No resolver pods found!"
          fi
          
          # Wait for all tekton system components to be ready
          echo "Waiting for all system components to be ready..."
          kubectl get pods -A
          
          # Wait for rollout to complete
          kubectl rollout status deployment/template-resolver -n tekton-pipelines-resolvers --timeout=2m

      - name: Validate template resolver with test-request
        run: task run:request

      - name: Run integration tests
        run: |
          # Run the e2e test and capture the exit code
          task run:pipelinerun || {
            EXIT_CODE=$?

            set -x
            # Dump the resolver logs regardless of failure reason
            echo "::group::Resolver Pod Logs (Last 100 lines)"
            kubectl get pods -n tekton-pipelines-resolvers -o wide
            kubectl get pods -n tekton-pipelines-resolvers -l app=template-resolver
            kubectl describe pods -n tekton-pipelines-resolvers -l app=template-resolver
            echo "Tests failed with exit code $EXIT_CODE - Dumping resolver pod logs:"
            RESOLVER_POD=$(kubectl get pods -n tekton-pipelines-resolvers -l app=template-resolver -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)
            if [ -n "$RESOLVER_POD" ]; then
              # Check pod status first
              echo "Pod status:"
              kubectl get pod -n tekton-pipelines-resolvers "$RESOLVER_POD" -o wide
              
              # Try to get logs with enhanced error handling
              echo "Pod logs:"
              # Check container names first
              CONTAINERS=$(kubectl get pod -n tekton-pipelines-resolvers "$RESOLVER_POD" -o jsonpath='{.spec.containers[*].name}')
              echo "Container names: $CONTAINERS"
              
              # Get logs with fallbacks and debug info
              if ! LOGS=$(kubectl logs -n tekton-pipelines-resolvers "$RESOLVER_POD" --tail=100 2>&1); then
                echo "Error getting logs: $LOGS"
                # Try all-containers flag
                echo "Trying --all-containers flag:"
                kubectl logs -n tekton-pipelines-resolvers "$RESOLVER_POD" --all-containers --tail=50 || echo "Still failed to get logs"
              else
                echo "$LOGS"
              fi
              
              # Check if pod is actually ready
              READY_STATUS=$(kubectl get pod -n tekton-pipelines-resolvers "$RESOLVER_POD" -o jsonpath='{.status.containerStatuses[0].ready}')
              PHASE=$(kubectl get pod -n tekton-pipelines-resolvers "$RESOLVER_POD" -o jsonpath='{.status.phase}')
              echo "Pod ready: $READY_STATUS, Pod phase: $PHASE"
              
              # Get details about container status
              CONTAINER_STATUS=$(kubectl get pod -n tekton-pipelines-resolvers "$RESOLVER_POD" -o json)
              echo "Container status details:"
              echo "$CONTAINER_STATUS" | jq '.status.containerStatuses'
              
              # First get the main container name
              echo "Getting main container name..."
              MAIN_CONTAINER=$(kubectl get pod -n tekton-pipelines-resolvers "$RESOLVER_POD" -o jsonpath='{.spec.containers[0].name}')
              echo "Main container name is: $MAIN_CONTAINER"
              
              # Try to get logs with fallback
              echo "Attempting to get logs for main container..."
              if kubectl logs -n tekton-pipelines-resolvers "$RESOLVER_POD" -c "$MAIN_CONTAINER" --tail=100; then
                echo "Successfully got logs from main container"
              else  
                echo "Failed to get logs from main container. Trying direct approach..."
                kubectl logs -n tekton-pipelines-resolvers "$RESOLVER_POD"
              fi
              
              # Try to view startup logs specially
              echo "Attempting to view startup logs..."
              kubectl logs -n tekton-pipelines-resolvers "$RESOLVER_POD" | head -50
              
              # Add a runtime debug log using exec
              echo "Adding runtime debug log..."
              kubectl exec -n tekton-pipelines-resolvers "$RESOLVER_POD" -- sh -c 'echo "EXEC DEBUG: Logging test from exec at $(date)" >> /tmp/debug.log' || echo "Failed to exec into pod"
              kubectl exec -n tekton-pipelines-resolvers "$RESOLVER_POD" -- sh -c 'cat /tmp/debug.log 2>/dev/null || echo "No debug log found"' || echo "Failed to read debug log"
              
              # Also check for timeout errors in the ResolutionRequest
              echo "::endgroup::"
              echo "::group::Resolution Request Status"
              PIPELINE_RUN_NAME="example-app-deployment"
              echo "Checking ResolutionRequest status for PipelineRun $PIPELINE_RUN_NAME..."
              LATEST_REQUEST=$(kubectl get resolutionrequest --sort-by=.metadata.creationTimestamp -o name 2>/dev/null | tail -n 1)
              if [ -n "$LATEST_REQUEST" ]; then
                REQUEST_NAME=${LATEST_REQUEST#*/}
                echo "Latest ResolutionRequest: $REQUEST_NAME"
                kubectl get resolutionrequest "$REQUEST_NAME" -o yaml
                
                # Check for detailed error message
                ERROR_MSG=$(kubectl get resolutionrequest "$REQUEST_NAME" -o jsonpath='{.status.conditions[0].message}' 2>/dev/null)
                if [ -n "$ERROR_MSG" ]; then
                  echo "Error message: $ERROR_MSG"
                fi
              else
                echo "No ResolutionRequest found"
              fi
            else
              echo "No resolver pod found in the tekton-pipelines-resolvers namespace"
              echo "All pods in the namespace:"
              kubectl get pods -n tekton-pipelines-resolvers
            fi
            echo "::endgroup::"
            
            # Also check if there were previous ResolutionRequests that might have failed
            echo "::group::All ResolutionRequests"
            kubectl get resolutionrequest
            echo "::endgroup::"
            
            # Preserve the original exit code
            exit $EXIT_CODE
          }
